 episode_step:  0
Obs:  [-0.03989699 -0.01164611 -0.04416545  0.02175319]
reward:  1.0
new_obs:  [-0.04012991 -0.20610777 -0.04373039  0.30018082]
 end iteration 
 episode_step:  1
Obs:  [-0.04012991 -0.20610777 -0.04373039  0.30018082]
reward:  1.0
new_obs:  [-0.04425207 -0.40058001 -0.03772677  0.57875767]
 end iteration 
 episode_step:  2
Obs:  [-0.04425207 -0.40058001 -0.03772677  0.57875767]
reward:  1.0
new_obs:  [-0.05226367 -0.20495021 -0.02615162  0.27443272]
 end iteration 
 episode_step:  3
Obs:  [-0.05226367 -0.20495021 -0.02615162  0.27443272]
reward:  1.0
new_obs:  [-0.05636267 -0.00946508 -0.02066296 -0.02638241]
 end iteration 
 episode_step:  4
Obs:  [-0.05636267 -0.00946508 -0.02066296 -0.02638241]
reward:  1.0
new_obs:  [-0.05655197  0.18594701 -0.02119061 -0.32551244]
 end iteration 
 episode_step:  5
Obs:  [-0.05655197  0.18594701 -0.02119061 -0.32551244]
reward:  1.0
new_obs:  [-0.05283303  0.38136416 -0.02770086 -0.62480194]
 end iteration 
 episode_step:  6
Obs:  [-0.05283303  0.38136416 -0.02770086 -0.62480194]
reward:  1.0
new_obs:  [-0.04520575  0.18663966 -0.0401969  -0.34097026]
 end iteration 
 episode_step:  7
Obs:  [-0.04520575  0.18663966 -0.0401969  -0.34097026]
reward:  1.0
new_obs:  [-0.04147296  0.3823098  -0.04701631 -0.64605307]
 end iteration 
 episode_step:  8
Obs:  [-0.04147296  0.3823098  -0.04701631 -0.64605307]
reward:  1.0
new_obs:  [-0.03382676  0.57805426 -0.05993737 -0.95316301]
 end iteration 
 episode_step:  9
Obs:  [-0.03382676  0.57805426 -0.05993737 -0.95316301]
reward:  1.0
new_obs:  [-0.02226567  0.77392922 -0.07900063 -1.26405889]
 end iteration 
 episode_step:  10
Obs:  [-0.02226567  0.77392922 -0.07900063 -1.26405889]
reward:  1.0
new_obs:  [-0.00678709  0.57990095 -0.10428181 -0.99712624]
 end iteration 
 episode_step:  11
Obs:  [-0.00678709  0.57990095 -0.10428181 -0.99712624]
reward:  1.0
new_obs:  [ 0.00481093  0.77625099 -0.12422433 -1.32065464]
 end iteration 
 episode_step:  12
Obs:  [ 0.00481093  0.77625099 -0.12422433 -1.32065464]
reward:  1.0
new_obs:  [ 0.02033595  0.58289869 -0.15063742 -1.06928922]
 end iteration 
 episode_step:  13
Obs:  [ 0.02033595  0.58289869 -0.15063742 -1.06928922]
reward:  1.0
new_obs:  [ 0.03199392  0.77965684 -0.17202321 -1.4052043 ]
 end iteration 
 episode_step:  14
Obs:  [ 0.03199392  0.77965684 -0.17202321 -1.4052043 ]
reward:  1.0
new_obs:  [ 0.04758706  0.9764458  -0.20012729 -1.74635673]
 end iteration 
 episode_step:  15
Obs:  [ 0.04758706  0.9764458  -0.20012729 -1.74635673]
reward:  1.0
new_obs:  [ 0.06711598  1.17320141 -0.23505443 -2.09404512]
 end iteration 
Batch len:  16
